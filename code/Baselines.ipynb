{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b02cd39-594a-4c84-9e21-01225e358389",
   "metadata": {},
   "source": [
    "## Importing Libraries and Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a66cd3-ca15-4b51-9f3d-ecff9127e929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e759c7e-e8b5-4951-8609-7bf2fce43aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd6e910-cb7a-4098-a4c6-c1487018c388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755e9b88-5766-45d8-814a-fafcbd5a87ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"ImperialIndians23/nlp_cw_data_unprocessed_augmented\")\n",
    "train_df = dataset['train'].to_pandas()\n",
    "validation_df = dataset['valid'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36076656-4892-4aff-a5cc-af4dac0dedeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14897aad-11d1-4a71-b278-cda4e948d3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[['text', 'label']]\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcc50f0-98bd-44ed-8a64-fc1c10ef7538",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = validation_df[['text', 'label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f91445-bfee-43fc-bbad-9db74ff20dd7",
   "metadata": {},
   "source": [
    "## Using TFID Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e9789a-2a9d-4ff5-b476-d258f4853873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "vec = vectorizer.fit_transform(train_df['text'])\n",
    "vec = np.array(vec.todense())\n",
    "\n",
    "X_train = vec\n",
    "y_train = train_df['label']\n",
    "\n",
    "vec = vectorizer.transform(validation_df['text'])\n",
    "vec = np.array(vec.todense())\n",
    "\n",
    "X_test = vec\n",
    "y_test = validation_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1d1368-6768-417a-9f01-74061d346672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a94e9c-b211-4c18-80ac-05cb1b8ecd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1987ab-7f2c-4a4b-baa5-60a622fadcf0",
   "metadata": {},
   "source": [
    "## Using Different Scikit-Learn Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f46a9e9-c415-44f7-ae0e-59570a61019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "\n",
    "model = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_preds))\n",
    "print('F1 score:', f1_score(y_test, y_preds, average=\"binary\"))\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc604d6b-5ed2-43bc-a585-b3e28796476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
    "print(\"F1 score:\", f1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634ffc58-77f0-425a-a6af-b590e394e0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
    "print(\"F1 score:\", f1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5ac211-0d3e-4b61-9544-e17f858bdcc6",
   "metadata": {},
   "source": [
    "## Using Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e7a5ac-ce18-41bd-977c-1a08385c196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "vectorizer = CountVectorizer()\n",
    "vec = vectorizer.fit_transform(train_df['text'])\n",
    "vec = np.array(vec.todense())\n",
    "\n",
    "X_train = vec\n",
    "y_train = train_df['label']\n",
    "\n",
    "vec = vectorizer.transform(validation_df['text'])\n",
    "vec = np.array(vec.todense())\n",
    "\n",
    "X_test = vec\n",
    "y_test = validation_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46503ec-e6df-4cf6-a18f-26f3fe1d34e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbd7a21-2bfa-4eeb-b7d8-c53b55aadb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "vectorizer = CountVectorizer(ngram_range=(2, 2))\n",
    "vec = vectorizer.fit_transform(train_df['text'])\n",
    "vec = np.array(vec.todense())\n",
    "\n",
    "X_train = vec\n",
    "y_train = train_df['label']\n",
    "\n",
    "vec = vectorizer.transform(validation_df['text'])\n",
    "vec = np.array(vec.todense())\n",
    "\n",
    "X_test = vec\n",
    "y_test = validation_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31dbeea-cdd4-4e5d-a464-005024eecd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eebeacc-8a0e-4417-b07e-f0665bdab0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = list(vectorizer.get_feature_names_out())\n",
    "for i in lis[0:100]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5f860e-83d6-48ec-ab9d-aee2c745f687",
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = list(vectorizer.get_feature_names_out())\n",
    "for i in lis[0:100]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3b571f-c58b-429e-9d4a-e3e11a5e744b",
   "metadata": {},
   "source": [
    "## Using Different Scikit-Learn Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80440073-16ba-44b2-8792-b373ff28ec11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
    "print(\"F1 score:\", f1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190b57df-e34a-499f-be30-09d0b80cadf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives = np.where((y_pred == 1) & (y_test == 0))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f221c27-61f5-43ab-aacb-c0e4ecdf037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_texts = train_df['text'][false_positives]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb50367-b8db-4c46-ac8f-7999fb329c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in false_positive_texts[0:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e341803-1072-4683-8f46-b5793daffc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_vectorized = vectorizer.transform(false_positive_texts)\n",
    "fp_sum = np.array(fp_vectorized.sum(axis=0)).flatten()\n",
    "unigrams_scores = dict(zip(vectorizer.get_feature_names_out(), fp_sum))\n",
    "sorted_unigrams = sorted(unigrams_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "top_n = 50\n",
    "print(sorted_unigrams[:top_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa67ff4a-fe7d-4536-a26a-b8b4aa620fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
    "print(\"F1 score:\", f1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434aa0c4-1c63-4d27-8928-ac63670a05ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
    "print(\"F1 score:\", f1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3498f6d4-3e74-4530-9d6b-eee96dcaf69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "\n",
    "model = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_preds))\n",
    "print('F1 score:', f1_score(y_test, y_preds, average=\"binary\"))\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dc59a8-2b99-467c-b120-249f07843710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "\n",
    "model = SVC().fit(X_train, y_train)\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_preds))\n",
    "print('F1 score:', f1_score(y_test, y_preds, average=\"binary\"))\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064c73d8-29ba-48f6-8c7c-55b0eeb6774c",
   "metadata": {},
   "source": [
    "## Using RoBERTa embeddings to train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ab3ba6-c421-4b0c-b3c3-cd218b37c08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"ImperialIndians23/nlp_cw_data_unprocessed_augmented\")\n",
    "train_df = dataset['train'].to_pandas()\n",
    "validation_df = dataset['valid'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b530c309-d101-44c2-9480-21df4bc0ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd00b9a7-904f-47e0-82c8-d9b6d7d0b229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "import torch\n",
    "from transformers import RobertaModel\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Assuming `df['text']` is your column with text data\n",
    "tokenized_data = tokenizer.batch_encode_plus(\n",
    "    train_df['text'].tolist(),\n",
    "    max_length=512,  # Max length for RoBERTa base\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Separate inputs for the model\n",
    "input_ids = tokenized_data['input_ids']\n",
    "attention_mask = tokenized_data['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f3dc4c-2c88-4ab7-82b1-63101a646725",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12766278-a878-4722-a878-d1dfa3a00d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb93f45f-e4cc-4756-b40a-65677cad0ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RobertaModel.from_pretrained('roberta-base')\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb601ac-9adc-4f49-9b70-1b5f213c04d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e5dc52-989c-4b64-859e-501d5b3193ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move tensors to the same device as the model\n",
    "input_ids = input_ids.to(model.device)\n",
    "attention_mask = attention_mask.to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39731872-49b3-4590-85ec-661151953e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(model, input_ids, attention_mask, batch_size=16):\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "    \n",
    "    # Initialize an empty tensor for storing embeddings\n",
    "    embeddings = torch.empty((0, model.config.hidden_size)).to(device)\n",
    "    \n",
    "    # Calculate total number of batches\n",
    "    total_batches = len(input_ids) // batch_size + (0 if len(input_ids) % batch_size == 0 else 1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(total_batches):\n",
    "            batch_input_ids = input_ids[i*batch_size : (i+1)*batch_size].to(device)\n",
    "            batch_attention_mask = attention_mask[i*batch_size : (i+1)*batch_size].to(device)\n",
    "            \n",
    "            batch_outputs = model(batch_input_ids, attention_mask=batch_attention_mask)\n",
    "            batch_embeddings = batch_outputs.last_hidden_state[:, 0, :]  # Extract the [CLS] token's embeddings\n",
    "            \n",
    "            embeddings = torch.cat((embeddings, batch_embeddings), dim=0)\n",
    "    \n",
    "    return embeddings.cpu().numpy()  # Move the concatenated embeddings back to CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aeef96-70ff-4cbc-8389-3a8e507b0d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = get_embeddings(model, input_ids, attention_mask, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5463707e-ed02-4fea-bc91-f23510deaae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(embeddings, train_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ced71ab-8ded-484b-9951-47a40aada97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move tensors to the same device as the model\n",
    "from transformers import RobertaTokenizer\n",
    "import torch\n",
    "from transformers import RobertaModel\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Assuming `df['text']` is your column with text data\n",
    "tokenized_data = tokenizer.batch_encode_plus(\n",
    "    validation_df['text'].tolist(),\n",
    "    max_length=512,  # Max length for RoBERTa base\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Separate inputs for the model\n",
    "input_ids_test = tokenized_data['input_ids']\n",
    "attention_mask_test = tokenized_data['attention_mask']\n",
    "input_ids_test = input_ids_test.to(model.device)\n",
    "attention_mask_test = attention_mask_test.to(model.device)\n",
    "embeddings = get_embeddings(model, input_ids_test, attention_mask_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fe0d67-a8f4-452b-b24c-116d49f823b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "y_pred = clf.predict(embeddings)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(validation_df['label'], y_pred))\n",
    "print(\"F1 score:\", f1_score(validation_df['label'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397f06ed-741c-4be1-809b-81a6e13d2f40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
